import sys
import os

# Thêm đường dẫn đến thư mục gốc của project
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.weaviate import WeaviateVectorStore
from llama_index.embeddings.google_genai import GoogleGenAIEmbedding
from llama_index.llms.google_genai import GoogleGenAI
import weaviate
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Import từ thư mục src
from src.global_setting import WEAVIATE_URL, WEAVIATE_CLASS_NAME

# Cấu hình API key từ environment variable
google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    raise ValueError("GOOGLE_API_KEY not found in environment variables. Please check your .env file.")

genai.configure(api_key=google_api_key)

def query_vector_database(query_text: str, top_k: int = 5):
    """Query vector database từ Weaviate"""
    
    try:
        # 1. Kết nối Weaviate với client v4
        weaviate_client = weaviate.connect_to_local(host="localhost", port=8080)
        
        if not weaviate_client.is_ready():
            raise Exception("Weaviate is not ready")
        
        print(f"✓ Connected to Weaviate at {WEAVIATE_URL}")
        
        # 2. Setup embedding model - sử dụng GoogleGenAI
        google_embedding = GoogleGenAIEmbedding(
            model_name="models/embedding-001",
            api_key=google_api_key
        )
        
        # 3. Setup LLM cho query engine
        google_llm = GoogleGenAI(
            model="models/gemini-1.5-flash",
            api_key=google_api_key,
            temperature=0.1
        )
        
        # 4. Build index từ Weaviate (Weaviate tự quản lý index)
        print("🔄 Connecting to Weaviate vector store...")
        vector_store = WeaviateVectorStore(
            weaviate_client=weaviate_client,
            index_name=WEAVIATE_CLASS_NAME,
            text_key="content"
        )
        
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        index = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
            embed_model=google_embedding
        )
        
        # 6. Tạo query engine với LLM và thực hiện truy vấn
        query_engine = index.as_query_engine(
            similarity_top_k=top_k,
            llm=google_llm
        )
        
        print(f"🔍 Querying: {query_text}")
        print(f"🤖 Using LLM: {google_llm.model} (Gemini-1.5-Flash)")
        print(f"📊 Retrieving top {top_k} similar chunks from Weaviate...")
        
        # Đây là nơi LLM được gọi để tạo câu trả lời từ retrieved context
        response = query_engine.query(query_text)
        
        print(f"\n📋 Answer (Generated by LLM): {response.response}")
        print(f"\n📚 Sources ({len(response.source_nodes)} results):")
        
        for i, node in enumerate(response.source_nodes, 1):
            print(f"\n{i}. Score: {node.score:.4f}")
            print(f"   Content: {node.text[:200]}...")
            if hasattr(node, 'metadata') and node.metadata:
                print(f"   Source: {node.metadata.get('filename', 'Unknown')}")
        
        # Đóng kết nối
        weaviate_client.close()
        
        return response
    
    except Exception as e:
        print(f"❌ Error querying vector database: {e}")
        import traceback
        traceback.print_exc()
        return None

def check_weaviate_status():
    """Kiểm tra trạng thái Weaviate và số lượng documents"""
    try:
        # Sử dụng Weaviate client v4
        client = weaviate.connect_to_local(host="localhost", port=8080)
        
        if client.is_ready():
            print(f"✅ Weaviate is running at {WEAVIATE_URL}")
            
            # Kiểm tra collections (v4 sử dụng collections thay vì classes)
            collections = client.collections.list_all()
            collection_names = [col.name for col in collections.values()]
            print(f"📋 Available collections: {collection_names}")
            
            # Đếm objects trong collection của chúng ta
            if WEAVIATE_CLASS_NAME in collection_names:
                collection = client.collections.get(WEAVIATE_CLASS_NAME)
                count = len(list(collection.iterator()))
                print(f"📊 Objects in {WEAVIATE_CLASS_NAME}: {count}")
            else:
                print(f"⚠️ Collection {WEAVIATE_CLASS_NAME} not found")
                
            client.close()
        else:
            print("❌ Weaviate is not ready")
            
    except Exception as e:
        print(f"❌ Error connecting to Weaviate: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("🔍 RAG Legal Consult System - Query Interface")
    print("=" * 50)
    
    # Kiểm tra trạng thái Weaviate
    check_weaviate_status()
    
    print("\n" + "=" * 50)
    
    # Một số câu hỏi mẫu
    sample_queries = [
        "Độ tuổi lao động tối thiểu là bao nhiêu?",
        "Quy định về thời gian làm việc",
        "Nghỉ phép năm được bao nhiêu ngày?",
        "Quyền và nghĩa vụ của người lao động"
    ]
    
    print("🎯 Sample queries:")
    for i, query in enumerate(sample_queries, 1):
        print(f"{i}. {query}")
    
    print("\n💡 Tips:")
    print("- Weaviate automatically manages indexing - no cache needed!")
    print("- First query might be slower (building connections)")
    print("- Subsequent queries will be faster with cached index")
    print("- Type 'quit' to exit")
    
    print("\n" + "=" * 50)
    
    # Interactive query
    while True:
        try:
            query = input("\n💬 Enter your question (or 'quit' to exit): ").strip()
            
            if query.lower() in ['quit', 'exit', 'q']:
                print("👋 Goodbye!")
                break
            
            if not query:
                continue
            
            # Thực hiện truy vấn
            response = query_vector_database(query)
            
            print("\n" + "-" * 50)
            
        except KeyboardInterrupt:
            print("\n👋 Goodbye!")
            break
