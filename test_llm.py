#!/usr/bin/env python3
# Test script Ä‘á»ƒ tháº¥y rÃµ LLM hoáº¡t Ä‘á»™ng

from query_system import query_vector_database

def test_llm_in_action():
    print("ğŸ”¬ Testing LLM in RAG System")
    print("=" * 50)
    
    # Test query
    query = "Äá»™ tuá»•i lao Ä‘á»™ng tá»‘i thiá»ƒu lÃ  bao nhiÃªu?"
    
    print(f"ğŸ“ Question: {query}")
    print("\nğŸ”„ RAG Process:")
    print("1. ğŸ” Vector search in Weaviate (Embedding)")
    print("2. ğŸ“Š Retrieve top similar chunks") 
    print("3. ğŸ¤– LLM generates answer from context")
    print("4. ğŸ“‹ Return final response")
    
    print("\n" + "=" * 50)
    
    # Execute query
    result = query_vector_database(query, top_k=3)
    
    if result:
        print("\nâœ… LLM successfully generated response from Weaviate context!")
    else:
        print("\nâŒ Failed to get LLM response")

if __name__ == "__main__":
    test_llm_in_action()
